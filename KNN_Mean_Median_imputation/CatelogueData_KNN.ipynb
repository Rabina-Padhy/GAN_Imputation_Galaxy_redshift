{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import timeit\n",
    "from math import ceil\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vals_test_df\n",
      "2.400169629289536\n",
      "Time to run the loop:  0.02784790000077919\n",
      "Iteration:  1\n",
      "2.5735985835423514\n",
      "Time to run the loop:  0.03297029999885126\n",
      "Iteration:  2\n",
      "2.7527455644308354\n",
      "Time to run the loop:  0.026584700000967132\n",
      "Iteration:  3\n",
      "2.652954567822694\n",
      "Time to run the loop:  0.02317340000081458\n",
      "Iteration:  4\n",
      "2.5135763679985565\n",
      "Time to run the loop:  0.023412600001393002\n",
      "Iteration:  5\n",
      "2.3884795593845816\n",
      "Time to run the loop:  0.03190390000054322\n",
      "Iteration:  6\n",
      "2.384214413911063\n",
      "Time to run the loop:  0.02869060000011814\n",
      "Iteration:  7\n",
      "2.4484507226970744\n",
      "Time to run the loop:  0.027597899999818765\n",
      "Iteration:  8\n",
      "2.4526041620229955\n",
      "Time to run the loop:  0.03126010000050883\n",
      "Iteration:  9\n",
      "2.4186510235122585\n",
      "Time to run the loop:  0.029709399999774178\n",
      "Iteration:  10\n",
      "2.389544656231002\n",
      "Time to run the loop:  0.031031300000904594\n",
      "Iteration:  11\n"
     ]
    }
   ],
   "source": [
    "#dataNames = ['vals_test_df', 'vals_test_df_test_type1', 'vals_test_df_test_type2']\n",
    "dataNames = ['vals_test_df']\n",
    "for dataName in dataNames:\n",
    "    if dataName =='vals_test_df':\n",
    "        train_dataName = 'vals_train_df'+'.csv'\n",
    "    elif dataName =='vals_test_df_test_type1':\n",
    "        train_dataName = 'vals_train_df_test_type1'+'.csv'\n",
    "    elif dataName =='vals_test_df_test_type2':\n",
    "        train_dataName = 'vals_train_df_test_type2'+'.csv'\n",
    "    file_name = dataName+'.csv'\n",
    "    missing_file_name = dataName+'_Missing_rate_0.15_Index.csv'\n",
    "    \n",
    "    #Load Dataset\n",
    "    original_data_x = np.loadtxt(file_name, delimiter=\",\", skiprows=1, usecols=(range(1, 10)))\n",
    "    miss_data_x = original_data_x.copy()\n",
    "    #print(original_data_x.shape)\n",
    "    \n",
    "    #Load the Missing Data Set for DataSet\n",
    "    data_m = np.loadtxt(missing_file_name, delimiter=\",\", skiprows=1)\n",
    "    miss_data_x[data_m == 0] = np.nan\n",
    "    \n",
    "    train_data_x = np.loadtxt(train_dataName, delimiter=\",\", skiprows=1, usecols=(range(1, 10)))\n",
    "                    \n",
    "    miss_data_x_new = np.concatenate([train_data_x, miss_data_x])\n",
    "    \n",
    "    #Convert to Data Frame\n",
    "    original_df = pd.DataFrame(data=original_data_x)\n",
    "    nans_df = pd.DataFrame(data=miss_data_x_new)\n",
    "    \n",
    "    #print(nans_df.shape)\n",
    "    #print(original_df.shape)\n",
    "    \n",
    "    \n",
    "    print(dataName)\n",
    "    for i in range(1,12):\n",
    "        # Create Imputer with K neighbors \n",
    "        imputer = KNNImputer(n_neighbors=i)\n",
    "        data_file_df_filled = imputer.fit_transform(nans_df)\n",
    "        if dataName ==  'vals_test_df':\n",
    "            data_file_df_filled_df = pd.DataFrame(data_file_df_filled[range(918,1311), :])\n",
    "        elif dataName ==  'vals_test_df_test_type1':\n",
    "            data_file_df_filled_df = pd.DataFrame(data_file_df_filled[range(495, 1311), :])\n",
    "        elif dataName ==  'vals_test_df_test_type2':\n",
    "            data_file_df_filled_df = pd.DataFrame(data_file_df_filled[range(816, 1311), :])\n",
    "        #print(data_file_df_filled_df.shape)\n",
    "        #data_file_df_filled_df.to_csv(\"KNN_imputated_catalogueData1.csv\", index = False)\n",
    "\n",
    "        X_train = pd.read_csv(train_dataName, usecols = [*range(1, 10)], header=None, skiprows=1)\n",
    "        y_train = pd.read_csv(train_dataName, usecols = [0], header=None, skiprows=1)\n",
    "        X_test = data_file_df_filled_df\n",
    "        y_test = pd.read_csv(file_name, usecols = [0], header=None, skiprows=1)\n",
    "\n",
    "        \n",
    "        #Target variable Encoded\n",
    "        train_target = y_train.values.ravel()\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        # Converting string labels into numbers.\n",
    "        target_train_encoded=le.fit_transform(train_target)\n",
    "        \n",
    "        #Target variable Encoded\n",
    "        test_target = y_test.values.ravel()\n",
    "        # Converting string labels into numbers.\n",
    "        target_test_encoded=le.fit_transform(test_target)\n",
    "        \n",
    "\n",
    "\n",
    "        start = timeit.default_timer()\n",
    "        #Create KNN Classifier\n",
    "        knn = KNeighborsClassifier(n_neighbors=i)\n",
    "\n",
    "        #Train the model using the training sets\n",
    "        knn.fit(X_train, target_train_encoded)\n",
    "\n",
    "        #Predict the response for test dataset\n",
    "        y_pred = knn.predict(X_test)\n",
    "\n",
    "        # Calculate RMSE\n",
    "        RMSE = np.sqrt(mean_squared_error(y_pred, target_test_encoded))\n",
    "        print(RMSE)\n",
    "\n",
    "        stop = timeit.default_timer()\n",
    "        timeTaken = stop - start\n",
    "        print('Time to run the loop: ', timeTaken)\n",
    "        print(\"Iteration: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.384214413911063\n",
      "Time to run the loop:  0.025803000000450993\n"
     ]
    }
   ],
   "source": [
    "dataName = 'vals_test_df'\n",
    "file_name = dataName+'.csv'\n",
    "if dataName =='vals_test_df':\n",
    "    train_dataName = 'vals_train_df'+'.csv'\n",
    "elif dataName =='vals_test_df_test_type1':\n",
    "    train_dataName = 'vals_train_df_test_type1'+'.csv'\n",
    "elif dataName =='vals_test_df_test_type2':\n",
    "    train_dataName = 'vals_train_df_test_type2'+'.csv'\n",
    "missing_file_name = dataName+'_Missing_rate_0.15_Index.csv'\n",
    "    \n",
    "#Load Dataset\n",
    "original_data_x = np.loadtxt(file_name, delimiter=\",\", skiprows=1, usecols=(range(1, 10)))\n",
    "miss_data_x = original_data_x.copy()\n",
    "#print(original_data_x.shape)\n",
    "    \n",
    "#Load the Missing Data Set for DataSet\n",
    "data_m = np.loadtxt(missing_file_name, delimiter=\",\", skiprows=1)\n",
    "miss_data_x[data_m == 0] = np.nan\n",
    "    \n",
    "train_data_x = np.loadtxt(train_dataName, delimiter=\",\", skiprows=1, usecols=(range(1, 10)))\n",
    "    #print(train_data_x.shape)   \n",
    "                    \n",
    "miss_data_x_new = np.concatenate([train_data_x, miss_data_x])\n",
    "    \n",
    "#Convert to Data Frame\n",
    "original_df = pd.DataFrame(data=original_data_x)\n",
    "nans_df = pd.DataFrame(data=miss_data_x_new)\n",
    "\n",
    "# Create Imputer with K neighbors \n",
    "imputer = KNNImputer(n_neighbors=7)\n",
    "data_file_df_filled = imputer.fit_transform(nans_df)\n",
    "if dataName ==  'vals_test_df':\n",
    "    data_file_df_filled_df = pd.DataFrame(data_file_df_filled[range(918,1311), :])\n",
    "elif dataName ==  'vals_test_df_test_type1':\n",
    "    data_file_df_filled_df = pd.DataFrame(data_file_df_filled[range(495, 1311), :])\n",
    "elif dataName ==  'vals_test_df_test_type2':\n",
    "    data_file_df_filled_df = pd.DataFrame(data_file_df_filled[range(816, 1311), :])\n",
    "        #print(data_file_df_filled_df.shape)\n",
    "\n",
    "\n",
    "                \n",
    "X_train = pd.read_csv(train_dataName, usecols = [*range(1, 10)], header=None, skiprows=1)\n",
    "y_train = pd.read_csv(train_dataName, usecols = [0], header=None, skiprows=1)\n",
    "X_test = data_file_df_filled_df\n",
    "y_test = pd.read_csv(file_name, usecols = [0], header=None, skiprows=1)\n",
    "        \n",
    "#Target variable Encoded\n",
    "train_target = y_train.values.ravel()\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Converting string labels into numbers.\n",
    "target_train_encoded=le.fit_transform(train_target)\n",
    "        \n",
    "#Target variable Encoded\n",
    "test_target = y_test.values.ravel()\n",
    "# Converting string labels into numbers.\n",
    "target_test_encoded=le.fit_transform(test_target)\n",
    "\n",
    "start = timeit.default_timer()        \n",
    "#Create KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, target_train_encoded)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "RMSE = np.sqrt(mean_squared_error(y_pred, target_test_encoded))\n",
    "print(RMSE)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "timeTaken = stop - start\n",
    "print('Time to run the loop: ', timeTaken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393, 10)\n"
     ]
    }
   ],
   "source": [
    "data_file_df_filled_df = pd.concat([y_test, data_file_df_filled_df], axis = 1)\n",
    "print(data_file_df_filled_df.shape)\n",
    "data_file_df_filled_df.to_csv(\"KNN_imputated_catalogueData1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Imputer with K neighbors \n",
    "imputer = KNNImputer(n_neighbors=7)\n",
    "data_file_df_filled = imputer.fit_transform(nans_df)\n",
    "data_file_df_filled_df = pd.DataFrame(data_file_df_filled[range(918,1311), :])\n",
    "print(data_file_df_filled_df.shape)\n",
    "data_file_df_filled_df.to_csv(\"KNN_imputated_catalogueData1.csv\", index = False)\n",
    "\n",
    "target = pd.read_csv(file_name, usecols = [0], header=None, skiprows=1)\n",
    "print(target.shape)\n",
    "\n",
    "X_train = pd.read_csv(\"vals_train_df.csv\", usecols = [*range(1, 10)], header=None, skiprows=1)\n",
    "y_train = pd.read_csv(\"vals_train_df.csv\", usecols = [0], header=None, skiprows=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "X_test = data_file_df_filled_df\n",
    "y_test = pd.read_csv(\"vals_test_df.csv\", usecols = [0], header=None, skiprows=1)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill the missing value with Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vals_test_df\n",
      "2.7555172505477366\n",
      "Time to run the loop:  0.03450979999979609\n",
      "Iteration:  1\n",
      "2.94089356519954\n",
      "Time to run the loop:  0.02177500000107102\n",
      "Iteration:  2\n",
      "3.045874864397326\n",
      "Time to run the loop:  0.021462099999553175\n",
      "Iteration:  3\n",
      "2.9456484487655707\n",
      "Time to run the loop:  0.022356899999067537\n",
      "Iteration:  4\n",
      "2.8149003751709234\n",
      "Time to run the loop:  0.021611899999697926\n",
      "Iteration:  5\n",
      "2.869068169780891\n",
      "Time to run the loop:  0.04123950000030163\n",
      "Iteration:  6\n",
      "2.8315740683998722\n",
      "Time to run the loop:  0.021851699999388075\n",
      "Iteration:  7\n",
      "2.8185138559592176\n",
      "Time to run the loop:  0.03313920000073267\n",
      "Iteration:  8\n",
      "2.8144483638672995\n",
      "Time to run the loop:  0.029753299999356386\n",
      "Iteration:  9\n",
      "2.783539402101834\n",
      "Time to run the loop:  0.036119599999437924\n",
      "Iteration:  10\n",
      "2.8062997106791285\n",
      "Time to run the loop:  0.03988039999967441\n",
      "Iteration:  11\n"
     ]
    }
   ],
   "source": [
    "#dataNames = ['vals_test_df', 'vals_test_df_test_type1', 'vals_test_df_test_type2']\n",
    "\n",
    "dataNames = ['vals_test_df']\n",
    "for dataName in dataNames:\n",
    "    if dataName =='vals_test_df':\n",
    "        train_dataName = 'vals_train_df'+'.csv'\n",
    "    elif dataName =='vals_test_df_test_type1':\n",
    "        train_dataName = 'vals_train_df_test_type1'+'.csv'\n",
    "    elif dataName =='vals_test_df_test_type2':\n",
    "        train_dataName = 'vals_train_df_test_type2'+'.csv'\n",
    "    file_name = dataName+'.csv'\n",
    "    missing_file_name = dataName+'_Missing_rate_0.15_Index.csv'\n",
    "    \n",
    "    #Load Dataset\n",
    "    original_data_x = np.loadtxt(file_name, delimiter=\",\", skiprows=1, usecols=(range(1, 10)))\n",
    "    miss_data_x = original_data_x.copy()\n",
    "    #print(original_data_x.shape)\n",
    "    \n",
    "    #Load the Missing Data Set for DataSet\n",
    "    data_m = np.loadtxt(missing_file_name, delimiter=\",\", skiprows=1)\n",
    "    miss_data_x[data_m == 0] = np.nan\n",
    "    \n",
    "    train_data_x = np.loadtxt(train_dataName, delimiter=\",\", skiprows=1, usecols=(range(1, 10)))\n",
    "    #print(train_data_x.shape)   \n",
    "                    \n",
    "    miss_data_x_new = np.concatenate([train_data_x, miss_data_x])\n",
    "    \n",
    "    #Convert to Data Frame\n",
    "    original_df = pd.DataFrame(data=original_data_x)\n",
    "    nans_df = pd.DataFrame(data=miss_data_x_new)\n",
    "    \n",
    "    #print(nans_df.shape)\n",
    "    #print(original_df.shape)\n",
    "    \n",
    "    \n",
    "    print(dataName)\n",
    "    for i in range(1,12):\n",
    "        # Impute with Mean\n",
    "        data_file_df_filled = nans_df.fillna(nans_df.mean())\n",
    "        if dataName ==  'vals_test_df':\n",
    "            #print(\"datasize\", data_file_df_filled.shape)\n",
    "            data_file_df_filled_df = data_file_df_filled.iloc[918:1311, :]\n",
    "        elif dataName ==  'vals_test_df_test_type1':\n",
    "            data_file_df_filled_df = data_file_df_filled.iloc[495:1311, :]\n",
    "        elif dataName ==  'vals_test_df_test_type2':\n",
    "            data_file_df_filled_df = data_file_df_filled.iloc[816:1311, :]\n",
    "            print(data_file_df_filled_df.shape)\n",
    "        #data_file_df_filled_df.to_csv(\"KNN_imputated_catalogueData1.csv\", index = False)\n",
    "\n",
    "                \n",
    "        X_train = pd.read_csv(train_dataName, usecols = [*range(1, 10)], header=None, skiprows=1)\n",
    "        y_train = pd.read_csv(train_dataName, usecols = [0], header=None, skiprows=1)\n",
    "        X_test = data_file_df_filled_df\n",
    "        y_test = pd.read_csv(file_name, usecols = [0], header=None, skiprows=1)\n",
    "        \n",
    "        #Target variable Encoded\n",
    "        train_target = y_train.values.ravel()\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        # Converting string labels into numbers.\n",
    "        target_train_encoded=le.fit_transform(train_target)\n",
    "        \n",
    "        #Target variable Encoded\n",
    "        test_target = y_test.values.ravel()\n",
    "        # Converting string labels into numbers.\n",
    "        target_test_encoded=le.fit_transform(test_target)\n",
    "        \n",
    "\n",
    "\n",
    "        start = timeit.default_timer()\n",
    "        #Create KNN Classifier\n",
    "        knn1 = KNeighborsClassifier(n_neighbors=i)\n",
    "\n",
    "        #Train the model using the training sets\n",
    "        knn1.fit(X_train, target_train_encoded)\n",
    "\n",
    "        #Predict the response for test dataset\n",
    "        y_pred = knn1.predict(X_test)\n",
    "\n",
    "        # Calculate RMSE\n",
    "        RMSE = np.sqrt(mean_squared_error(y_pred, target_test_encoded))\n",
    "        print(RMSE)\n",
    "\n",
    "        stop = timeit.default_timer()\n",
    "        timeTaken = stop - start\n",
    "        print('Time to run the loop: ', timeTaken)\n",
    "        print(\"Iteration: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.783539402101834\n",
      "Time to run the loop:  0.02809220000017376\n"
     ]
    }
   ],
   "source": [
    "dataName = 'vals_test_df'\n",
    "\n",
    "if dataName =='vals_test_df':\n",
    "    train_dataName = 'vals_train_df'+'.csv'\n",
    "elif dataName =='vals_test_df_test_type1':\n",
    "    train_dataName = 'vals_train_df_test_type1'+'.csv'\n",
    "elif dataName =='vals_test_df_test_type2':\n",
    "    train_dataName = 'vals_train_df_test_type2'+'.csv'\n",
    "file_name = dataName+'.csv'\n",
    "missing_file_name = dataName+'_Missing_rate_0.15_Index.csv'\n",
    "    \n",
    "#Load Dataset\n",
    "original_data_x = np.loadtxt(file_name, delimiter=\",\", skiprows=1, usecols=(range(1, 10)))\n",
    "miss_data_x = original_data_x.copy()\n",
    "#print(original_data_x.shape)\n",
    "    \n",
    "#Load the Missing Data Set for DataSet\n",
    "data_m = np.loadtxt(missing_file_name, delimiter=\",\", skiprows=1)\n",
    "miss_data_x[data_m == 0] = np.nan\n",
    "    \n",
    "train_data_x = np.loadtxt(train_dataName, delimiter=\",\", skiprows=1, usecols=(range(1, 10)))\n",
    "#print(train_data_x.shape)   \n",
    "                    \n",
    "miss_data_x_new = np.concatenate([train_data_x, miss_data_x])\n",
    "    \n",
    "#Convert to Data Frame\n",
    "original_df = pd.DataFrame(data=original_data_x)\n",
    "nans_df = pd.DataFrame(data=miss_data_x_new)\n",
    "\n",
    "# Impute with Mean\n",
    "data_file_df_filled = nans_df.fillna(nans_df.mean())\n",
    "if dataName ==  'vals_test_df':\n",
    "    #print(\"datasize\", data_file_df_filled.shape)\n",
    "    data_file_df_filled_df = data_file_df_filled.iloc[918:1311, :]\n",
    "elif dataName ==  'vals_test_df_test_type1':\n",
    "    data_file_df_filled_df = data_file_df_filled.iloc[495:1311, :]\n",
    "elif dataName ==  'vals_test_df_test_type2':\n",
    "    data_file_df_filled_df = data_file_df_filled.iloc[816:1311, :]\n",
    "#print(data_file_df_filled_df.shape)\n",
    "\n",
    "\n",
    "X_train = pd.read_csv(train_dataName, usecols = [*range(1, 10)], header=None, skiprows=1)\n",
    "y_train = pd.read_csv(train_dataName, usecols = [0], header=None, skiprows=1)\n",
    "X_test = data_file_df_filled_df\n",
    "y_test = pd.read_csv(file_name, usecols = [0], header=None, skiprows=1)\n",
    "        \n",
    "#Target variable Encoded\n",
    "train_target = y_train.values.ravel()\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Converting string labels into numbers.\n",
    "target_train_encoded=le.fit_transform(train_target)\n",
    "        \n",
    "#Target variable Encoded\n",
    "test_target = y_test.values.ravel()\n",
    "# Converting string labels into numbers.\n",
    "target_test_encoded=le.fit_transform(test_target)\n",
    "        \n",
    "\n",
    "\n",
    "start = timeit.default_timer()\n",
    "#Create KNN Classifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn1.fit(X_train, target_train_encoded)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn1.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "RMSE = np.sqrt(mean_squared_error(y_pred, target_test_encoded))\n",
    "print(RMSE)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "timeTaken = stop - start\n",
    "print('Time to run the loop: ', timeTaken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(786, 10)\n"
     ]
    }
   ],
   "source": [
    "data_file_df_filled_df = pd.concat([y_test, data_file_df_filled_df], axis = 1, ignore_index=True)\n",
    "print(data_file_df_filled_df.shape)\n",
    "data_file_df_filled_df.to_csv(\"Mean_imputated_catalogueData1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1311, 9)\n",
      "                                                      0  \\\n",
      "918                                           -0.126719   \n",
      "919   <bound method DataFrame.mean of              0...   \n",
      "920                                           -0.132593   \n",
      "921                                           -0.137784   \n",
      "922                                           -0.133823   \n",
      "...                                                 ...   \n",
      "1306                                          -0.133413   \n",
      "1307                                          -0.133686   \n",
      "1308  <bound method DataFrame.mean of              0...   \n",
      "1309                                          -0.130271   \n",
      "1310                                          -0.131227   \n",
      "\n",
      "                                                      1  \\\n",
      "918                                           -0.181074   \n",
      "919   <bound method DataFrame.mean of              0...   \n",
      "920                                          -0.0289773   \n",
      "921   <bound method DataFrame.mean of              0...   \n",
      "922   <bound method DataFrame.mean of              0...   \n",
      "...                                                 ...   \n",
      "1306  <bound method DataFrame.mean of              0...   \n",
      "1307                                          -0.278383   \n",
      "1308                                            0.53358   \n",
      "1309                                          -0.297117   \n",
      "1310  <bound method DataFrame.mean of              0...   \n",
      "\n",
      "                                                      2  \\\n",
      "918                                          -0.0971537   \n",
      "919                                           -0.634563   \n",
      "920                                            -0.15178   \n",
      "921   <bound method DataFrame.mean of              0...   \n",
      "922                                           -0.372267   \n",
      "...                                                 ...   \n",
      "1306                                          -0.445737   \n",
      "1307                                          -0.187447   \n",
      "1308                                           0.295756   \n",
      "1309                                          -0.140793   \n",
      "1310  <bound method DataFrame.mean of              0...   \n",
      "\n",
      "                                                      3  \\\n",
      "918                                           -0.191932   \n",
      "919                                           -0.381705   \n",
      "920                                          -0.0717168   \n",
      "921                                           -0.384738   \n",
      "922                                           -0.293054   \n",
      "...                                                 ...   \n",
      "1306                                            -0.2669   \n",
      "1307  <bound method DataFrame.mean of              0...   \n",
      "1308                                           0.218159   \n",
      "1309                                          -0.207411   \n",
      "1310                                          -0.240698   \n",
      "\n",
      "                                                      4  \\\n",
      "918                                            0.207482   \n",
      "919                                           -0.408211   \n",
      "920                                            0.206568   \n",
      "921                                           -0.469577   \n",
      "922                                           -0.326369   \n",
      "...                                                 ...   \n",
      "1306                                          -0.384126   \n",
      "1307  <bound method DataFrame.mean of              0...   \n",
      "1308                                            1.08097   \n",
      "1309                                          -0.115513   \n",
      "1310                                          0.0717851   \n",
      "\n",
      "                                                      5  \\\n",
      "918                                           -0.531359   \n",
      "919                                             1.21007   \n",
      "920   <bound method DataFrame.mean of              0...   \n",
      "921                                             1.38366   \n",
      "922                                             0.51382   \n",
      "...                                                 ...   \n",
      "1306  <bound method DataFrame.mean of              0...   \n",
      "1307                                          -0.707435   \n",
      "1308                                           -1.15638   \n",
      "1309                                         -0.0409253   \n",
      "1310                                          -0.686795   \n",
      "\n",
      "                                                      6  \\\n",
      "918                                           -0.400629   \n",
      "919                                             1.83709   \n",
      "920                                           -0.409262   \n",
      "921                                             1.63894   \n",
      "922                                            0.543772   \n",
      "...                                                 ...   \n",
      "1306  <bound method DataFrame.mean of              0...   \n",
      "1307                                          -0.530267   \n",
      "1308                                           -1.05958   \n",
      "1309                                         -0.0940477   \n",
      "1310                                          -0.437336   \n",
      "\n",
      "                                                      7  \\\n",
      "918                                           -0.356314   \n",
      "919                                             2.30696   \n",
      "920   <bound method DataFrame.mean of              0...   \n",
      "921                                             1.36914   \n",
      "922                                            0.691152   \n",
      "...                                                 ...   \n",
      "1306                                           0.450063   \n",
      "1307                                          -0.447604   \n",
      "1308                                           -1.04826   \n",
      "1309                                          -0.120217   \n",
      "1310                                          -0.309889   \n",
      "\n",
      "                                                      8  \n",
      "918   <bound method DataFrame.mean of              0...  \n",
      "919                                             2.16042  \n",
      "920                                           -0.363255  \n",
      "921                                             1.23811  \n",
      "922   <bound method DataFrame.mean of              0...  \n",
      "...                                                 ...  \n",
      "1306                                           0.567495  \n",
      "1307                                          -0.330563  \n",
      "1308                                           -1.00136  \n",
      "1309                                          -0.213076  \n",
      "1310                                          -0.183429  \n",
      "\n",
      "[393 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "data_file_df_filled = nans_df.fillna(nans_df.mean)\n",
    "print(data_file_df_filled.shape)\n",
    "data_file_df_filled_df = data_file_df_filled.iloc[918:1311, :]\n",
    "\n",
    "#data_file_df_filled_df['0'] = pd.to_numeric(data_file_df_filled_df['0'], errors='coerce')\n",
    "print(data_file_df_filled_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill with Median Value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vals_test_df\n",
      "2.72953873015008\n",
      "Time to run the loop:  0.02694549999978335\n",
      "Iteration:  1\n",
      "2.873056373656572\n",
      "Time to run the loop:  0.024063299999397714\n",
      "Iteration:  2\n",
      "3.00339078944061\n",
      "Time to run the loop:  0.02066940000077011\n",
      "Iteration:  3\n",
      "2.9538434013492756\n",
      "Time to run the loop:  0.02095279999957711\n",
      "Iteration:  4\n",
      "2.7853670709803726\n",
      "Time to run the loop:  0.020809599998756312\n",
      "Iteration:  5\n",
      "2.7743829976792505\n",
      "Time to run the loop:  0.02572189999955299\n",
      "Iteration:  6\n",
      "2.7990365481651676\n",
      "Time to run the loop:  0.02390910000030999\n",
      "Iteration:  7\n",
      "2.7508962222238216\n",
      "Time to run the loop:  0.022013699999661185\n",
      "Iteration:  8\n",
      "2.724873646018921\n",
      "Time to run the loop:  0.021676700000170968\n",
      "Iteration:  9\n",
      "2.666348581538003\n",
      "Time to run the loop:  0.02703329999894777\n",
      "Iteration:  10\n",
      "2.628866956661552\n",
      "Time to run the loop:  0.02199540000037814\n",
      "Iteration:  11\n"
     ]
    }
   ],
   "source": [
    "#dataNames = ['vals_test_df', 'vals_test_df_test_type1', 'vals_test_df_test_type2']\n",
    "\n",
    "dataNames = ['vals_test_df']\n",
    "for dataName in dataNames:\n",
    "    if dataName =='vals_test_df':\n",
    "        train_dataName = 'vals_train_df'+'.csv'\n",
    "    elif dataName =='vals_test_df_test_type1':\n",
    "        train_dataName = 'vals_train_df_test_type1'+'.csv'\n",
    "    elif dataName =='vals_test_df_test_type2':\n",
    "        train_dataName = 'vals_train_df_test_type2'+'.csv'\n",
    "    file_name = dataName+'.csv'\n",
    "    missing_file_name = dataName+'_Missing_rate_0.15_Index.csv'\n",
    "    \n",
    "    #Load Dataset\n",
    "    original_data_x = np.loadtxt(file_name, delimiter=\",\", skiprows=1, usecols=(range(1, 10)))\n",
    "    miss_data_x = original_data_x.copy()\n",
    "    #print(original_data_x.shape)\n",
    "    \n",
    "    #Load the Missing Data Set for DataSet\n",
    "    data_m = np.loadtxt(missing_file_name, delimiter=\",\", skiprows=1)\n",
    "    miss_data_x[data_m == 0] = np.nan\n",
    "    \n",
    "    train_data_x = np.loadtxt(train_dataName, delimiter=\",\", skiprows=1, usecols=(range(1, 10)))\n",
    "    #print(train_data_x.shape)   \n",
    "                    \n",
    "    miss_data_x_new = np.concatenate([train_data_x, miss_data_x])\n",
    "    \n",
    "    #Convert to Data Frame\n",
    "    original_df = pd.DataFrame(data=original_data_x)\n",
    "    nans_df = pd.DataFrame(data=miss_data_x_new)\n",
    "    \n",
    "    #print(nans_df.shape)\n",
    "    #print(original_df.shape)\n",
    "    \n",
    "    \n",
    "    print(dataName)\n",
    "    for i in range(1,12):\n",
    "        # Impute with Mean\n",
    "        data_file_df_filled = nans_df.fillna(nans_df.median())\n",
    "        if dataName ==  'vals_test_df':\n",
    "            #print(\"datasize\", data_file_df_filled.shape)\n",
    "            data_file_df_filled_df = data_file_df_filled.iloc[918:1311, :]\n",
    "        elif dataName ==  'vals_test_df_test_type1':\n",
    "            data_file_df_filled_df = data_file_df_filled.iloc[495:1311, :]\n",
    "        elif dataName ==  'vals_test_df_test_type2':\n",
    "            data_file_df_filled_df = data_file_df_filled.iloc[816:1311, :]\n",
    "        #print(data_file_df_filled_df.shape)\n",
    "        #data_file_df_filled_df.to_csv(\"KNN_imputated_catalogueData1.csv\", index = False)\n",
    "\n",
    "                \n",
    "        X_train = pd.read_csv(train_dataName, usecols = [*range(1, 10)], header=None, skiprows=1)\n",
    "        y_train = pd.read_csv(train_dataName, usecols = [0], header=None, skiprows=1)\n",
    "        X_test = data_file_df_filled_df\n",
    "        y_test = pd.read_csv(file_name, usecols = [0], header=None, skiprows=1)\n",
    "        \n",
    "        #Target variable Encoded\n",
    "        train_target = y_train.values.ravel()\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        # Converting string labels into numbers.\n",
    "        target_train_encoded=le.fit_transform(train_target)\n",
    "        \n",
    "        #Target variable Encoded\n",
    "        test_target = y_test.values.ravel()\n",
    "        # Converting string labels into numbers.\n",
    "        target_test_encoded=le.fit_transform(test_target)\n",
    "        \n",
    "\n",
    "\n",
    "        start = timeit.default_timer()\n",
    "        #Create KNN Classifier\n",
    "        knn1 = KNeighborsClassifier(n_neighbors=i)\n",
    "\n",
    "        #Train the model using the training sets\n",
    "        knn1.fit(X_train, target_train_encoded)\n",
    "\n",
    "        #Predict the response for test dataset\n",
    "        y_pred = knn1.predict(X_test)\n",
    "\n",
    "        # Calculate RMSE\n",
    "        RMSE = np.sqrt(mean_squared_error(y_pred, target_test_encoded))\n",
    "        print(RMSE)\n",
    "\n",
    "        stop = timeit.default_timer()\n",
    "        timeTaken = stop - start\n",
    "        print('Time to run the loop: ', timeTaken)\n",
    "        print(\"Iteration: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.628866956661552\n",
      "Time to run the loop:  0.025638000000981265\n"
     ]
    }
   ],
   "source": [
    "dataName = 'vals_test_df'\n",
    "if dataName =='vals_test_df':\n",
    "    train_dataName = 'vals_train_df'+'.csv'\n",
    "elif dataName =='vals_test_df_test_type1':\n",
    "    train_dataName = 'vals_train_df_test_type1'+'.csv'\n",
    "elif dataName =='vals_test_df_test_type2':\n",
    "    train_dataName = 'vals_train_df_test_type2'+'.csv'\n",
    "file_name = dataName+'.csv'\n",
    "missing_file_name = dataName+'_Missing_rate_0.15_Index.csv'\n",
    "    \n",
    "#Load Dataset\n",
    "original_data_x = np.loadtxt(file_name, delimiter=\",\", skiprows=1, usecols=(range(1, 10)))\n",
    "miss_data_x = original_data_x.copy()\n",
    "#print(original_data_x.shape)\n",
    "    \n",
    "#Load the Missing Data Set for DataSet\n",
    "data_m = np.loadtxt(missing_file_name, delimiter=\",\", skiprows=1)\n",
    "miss_data_x[data_m == 0] = np.nan\n",
    "    \n",
    "train_data_x = np.loadtxt(train_dataName, delimiter=\",\", skiprows=1, usecols=(range(1, 10)))\n",
    "#print(train_data_x.shape)   \n",
    "                    \n",
    "miss_data_x_new = np.concatenate([train_data_x, miss_data_x])\n",
    "    \n",
    "#Convert to Data Frame\n",
    "original_df = pd.DataFrame(data=original_data_x)\n",
    "nans_df = pd.DataFrame(data=miss_data_x_new)\n",
    "# Impute with Mean\n",
    "data_file_df_filled = nans_df.fillna(nans_df.median())\n",
    "if dataName ==  'vals_test_df':\n",
    "    #print(\"datasize\", data_file_df_filled.shape)\n",
    "    data_file_df_filled_df = data_file_df_filled.iloc[918:1311, :]\n",
    "elif dataName ==  'vals_test_df_test_type1':\n",
    "    data_file_df_filled_df = data_file_df_filled.iloc[495:1311, :]\n",
    "elif dataName ==  'vals_test_df_test_type2':\n",
    "    data_file_df_filled_df = data_file_df_filled.iloc[816:1311, :]\n",
    "#print(data_file_df_filled_df.shape)\n",
    "\n",
    "\n",
    "                \n",
    "X_train = pd.read_csv(train_dataName, usecols = [*range(1, 10)], header=None, skiprows=1)\n",
    "y_train = pd.read_csv(train_dataName, usecols = [0], header=None, skiprows=1)\n",
    "X_test = data_file_df_filled_df\n",
    "y_test = pd.read_csv(file_name, usecols = [0], header=None, skiprows=1)\n",
    "        \n",
    "#Target variable Encoded\n",
    "train_target = y_train.values.ravel()\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Converting string labels into numbers.\n",
    "target_train_encoded=le.fit_transform(train_target)\n",
    "        \n",
    "#Target variable Encoded\n",
    "test_target = y_test.values.ravel()\n",
    "# Converting string labels into numbers.\n",
    "target_test_encoded=le.fit_transform(test_target)\n",
    "        \n",
    "\n",
    "\n",
    "start = timeit.default_timer()\n",
    "#Create KNN Classifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn1.fit(X_train, target_train_encoded)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn1.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "RMSE = np.sqrt(mean_squared_error(y_pred, target_test_encoded))\n",
    "print(RMSE)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "timeTaken = stop - start\n",
    "print('Time to run the loop: ', timeTaken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(786, 10)\n"
     ]
    }
   ],
   "source": [
    "data_file_df_filled_df = pd.concat([y_test, data_file_df_filled_df], axis = 1, ignore_index=True)\n",
    "print(data_file_df_filled_df.shape)\n",
    "data_file_df_filled_df.to_csv(\"Median_imputated_catalogueData1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
